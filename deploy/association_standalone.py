#!/usr/bin/env python


import contextlib as __stickytape_contextlib

@__stickytape_contextlib.contextmanager
def __stickytape_temporary_dir():
    import tempfile
    import shutil
    dir_path = tempfile.mkdtemp()
    try:
        yield dir_path
    finally:
        shutil.rmtree(dir_path)

with __stickytape_temporary_dir() as __stickytape_working_dir:
    def __stickytape_write_module(path, contents):
        import os, os.path

        def make_package(path):
            parts = path.split("/")
            partial_path = __stickytape_working_dir
            for part in parts:
                partial_path = os.path.join(partial_path, part)
                if not os.path.exists(partial_path):
                    os.mkdir(partial_path)
                    open(os.path.join(partial_path, "__init__.py"), "w").write("\n")

        make_package(os.path.dirname(path))

        full_path = os.path.join(__stickytape_working_dir, path)
        with open(full_path, "w") as module_file:
            module_file.write(contents)

    import sys as __stickytape_sys
    __stickytape_sys.path.insert(0, __stickytape_working_dir)

    __stickytape_write_module('knowledge/util/print.py', "\nimport math\nimport os\nimport re\nimport time\n\nfrom datetime import datetime\nfrom getpass import getpass\n\nclass PrintUtil:\n    persist_str = ''\n    persist_rows = 0\n    logfile = None\n    silent = False\n    FRMTS = {\n        'bold': 1,\n        'faint': 2,\n        'italic': 3,\n        'underline': 4,\n        'strikethrough': 9\n    }\n\n    @classmethod\n    def silence(self):\n        self.silent = True\n\n    @classmethod\n    def unsilence(self):\n        self.silence = False\n\n    @classmethod\n    def log(self, filename):\n        self.logfile = open(filename, 'w')\n\n    @classmethod\n    def render_width(self, string):\n        # https://en.wikipedia.org/wiki/ANSI_escape_code\n        return len(re.sub('\\\\x1b\\[[0-9]*m', '', string))\n\n    @classmethod\n    def render_rows(self, string):\n        rows, cols = os.popen('stty size', 'r').read().split()\n        rows = int(rows)\n        cols = int(cols)\n        return sum(self.render_width(line) // cols + 1 for line \n            in string.split('\\n'))\n\n    @classmethod\n    def table(self, tbl, align='l', pad=1, border=False, wrap=False, hrule=None):\n        if align in ('r', 'l'):\n            aligns = [align] * len(tbl[0])\n        elif type(align) in (list, tuple) and all([a in ('r', 'l') for a in align]):\n            aligns = align \n        else:\n            return ''\n        if type(pad) is int:\n            pads = [pad] * len(tbl[0])\n        elif type(pad) in (list, tuple) and all([type(p) is int for p in pad]):\n            pads = pad\n        else:\n            return ''\n        tbl = [[str(cell) for cell in row] for row in tbl]\n        widths = [max([self.render_width(cell) for cell in col]) \n            for col in list(map(list, zip(*tbl)))]\n        if border:\n            if hrule is None:\n                hrules = [0]*(len(tbl))\n            elif (type(hrule) in (list, tuple) \n                    and all([type(h) is int for h in hrules])):\n                hrules = [1 if i in hrule else 0 for i in range(len(tbl)-1)] + [0]\n            top = '+' + '+'.join('-'*(w+p*2) for w, p in zip(widths, pads)) + '+'\n            return (top + '\\n' +\n                '\\n'.join('|' + '|'.join([' '*p + cell.ljust(w) + ' '*p \n                if a == 'l' else ' '*p + cell.rjust(w) + ' '*p\n                for cell, w, a, p in zip(row, widths, aligns, pads)]) + \n                (f'|\\n{top}' if hrule else '|')\n                for row, hrule in zip(tbl, hrules)) + '\\n' + top)\n        else:\n            return '\\n'.join(''.join(cell.ljust(w) + ' '*p\n                if a == 'l' else cell.rjust(w) + ' '*p\n                for cell, w, a, p in zip(row, widths, aligns, pads)) \n                for row in tbl)\n    \n    @classmethod\n    def time(self, string):\n        date = datetime.now()\n        return ('[' + date.strftime('%H:%M:%S:') + \n            str(date.microsecond // 1000).zfill(3) +\n            '] ' + string)\n\n    @classmethod\n    def format(self, string, *frmts):\n        # https://en.wikipedia.org/wiki/ANSI_escape_code\n        codes = tuple(self.FRMTS[frmt] for frmt in frmts if frmt in self.FRMTS)\n        return ('\\x1b[%sm'*len(codes) % codes) + string + '\\x1b[0m'        \n    \n    @classmethod\n    def progress(self, string, prog):\n        prog = min(1, max(0, prog))\n        perc = 100 * prog\n        return ( string + ' [' + \n                '=' * int(perc // 5) + \n                '_' * int(20 - perc // 5) + \n                '] ' + str(round(perc, 1)) + '%')\n\n    @classmethod\n    def clear(self, rows=None):\n        if rows is None:\n            rows, cols = os.popen('stty size', 'r').read().split()\n            rows = int(rows)\n            cols = int(cols)\n        print('\\n'*(rows-1) + '\\033[F'*rows, end='\\r')\n\n    @classmethod\n    def delete(self, rows):\n        pass\n\n    @classmethod\n    def push(self):\n        persist = self.persist_str\n        self.print('', persist=True, replace=True)\n        self.print(persist)\n\n    @classmethod\n    def printer(self, *args, **kwargs):\n        def custom_print(string, *margs, **mkwarg):\n            self.print(string, *args, *margs, **kwargs, **mkwarg)\n        return custom_print\n\n    @classmethod\n    def getpass(self, *args, **kwargs):\n        return self.print(*args, **kwargs, prompt=True, password=True)\n\n    @classmethod\n    def input(self, *args, **kwargs):\n        return self.print(*args, **kwargs, prompt=True)\n\n    @classmethod\n    def print(self, string='', persist=False, replace=False, time=False, \n            progress=None, frmt=None, inquiry=False, force=False, prompt=False,\n            password=False):\n        if self.silent and not force:\n            return\n        string = str(string)\n        rows, cols = os.popen('stty size', 'r').read().split()\n        rows = int(rows)\n        cols = int(cols)\n        print(('\\033[F'+' '*cols)*self.persist_rows, end='\\r')\n        if time:\n            string = self.time(string)\n        if progress is not None:\n            string = self.progress(string, progress)\n        if self.logfile is not None and not persist:\n            self.logfile.write(string + '\\n')\n            self.logfile.flush()\n        if frmt is not None:\n            if type(frmt) is list:\n                string = self.format(string, *frmt)\n            elif type(frmt) is str:\n                string = self.format(string, frmt)\n        if persist:\n            if not replace and self.persist_rows:\n                self.persist_str += '\\n' + string\n            else:\n                self.persist_str = string\n            self.persist_rows = self.render_rows(self.persist_str)\n        elif prompt:\n            if password:\n                return getpass(string)\n            else:\n                return input(string)\n        elif inquiry:\n            response = input(string).lower()\n            return response == 'y' or response == 'yes'\n        else:\n            print(string)\n        if self.persist_rows:\n            print(self.persist_str)\n")
    __stickytape_write_module('knowledge/__init__.py', '')
    __stickytape_write_module('knowledge/util/__init__.py', '')
    __stickytape_write_module('knowledge/util/config.py', '\nimport json\nimport re\nimport os\n\nfrom knowledge.util.error import ConfigError\nfrom knowledge.util.print import PrintUtil as pr\n\n\nclass ConfigUtil:\n    \'\'\'static class used to verify config to specs for runner\n\n    also includes some useful tools for handling config parameters\n    \'\'\'\n\n    types = {\'str\': str, \'int\': int, \'bool\': bool, \'dict\': dict,\n        \'list\': list, \'float\': float, \'null\': None}\n\n\n    @classmethod\n    def file_readable(self, filepath):\n        \'check that file can be read\'\n        return os.access(filepath, os.R_OK)\n\n\n    @classmethod\n    def file_exists(self, filepath):\n        \'check that file exists\'\n        return os.path.exists(filepath)\n    \n\n    @classmethod\n    def file_writable(self, filepath):\n        \'check that file is writable\'\n        if self.file_exists(filepath):\n            if os.path.isfile(filepath):\n                return os.access(filepath, os.W_OK)\n            else:\n                return False \n        \n        pdir = os.path.dirname(filepath)\n        if not pdir: \n            pdir = \'.\'\n        return os.access(pdir, os.W_OK)\n\n\n    @classmethod\n    def load_config(self, filepath):\n        \'load a config file; catches file and JSON errors\'\n        try:\n            with open(filepath) as handle:\n                return json.load(handle)\n        except FileNotFoundError as err:\n            pr.print(f\'Config file "{filepath}" does not exist; \'\n                \'terminating model run.\', time=True)\n            raise err\n        except json.JSONDecodeError as err:\n            pr.print(f\'Config file "{filepath}" is not valid json; \'\n                \'terminating model run.\', time=True)\n            raise err\n        \n\n    @classmethod\n    def load_specs(self, filepath):\n        \'load a config file; catches file and JSON errors\'\n        try:\n            with open(filepath) as handle:\n                return json.load(handle)\n        except FileNotFoundError as err:\n            pr.print(f\'Specs file "{filepath}" does not exist; \'\n                \'terminating model run.\', time=True)\n            raise err\n        except json.JSONDecodeError as err:\n            pr.print(f\'Specs file "{filepath}" is not valid json; \'\n                \'terminating model run.\', time=True)\n            raise err\n\n\n    @classmethod\n    def verify_config(self, specs, config, name=\'\'):\n        \'\'\'recursively validates a specifications dict to a configuration dict\n\n        Parameters\n        ----------\n        specs: dict\n            The dict representing a JSON specifications file.\n\n        config: dict\n            The dict representing a JSON configurations file; will be checked\n            against the specifications file.\n\n        Returns\n        -------\n        config: dict\n            A new dict representing the JSON configuration file with any missing\n            default values added onto it.\n        \'\'\'\n\n        for attr in config.keys():\n            if attr not in specs.keys():\n                if type(attr) is int:\n                    path = f\'{name}[{attr}]\' if name != \'\' else attr\n                else:\n                    path = f\'{name}.{attr}\' if name != \'\' else attr\n                pr.print(f\'Warning: config parameter "{path}" is not \'\n                    \'in model specifications.\', time=True)\n\n        for attr, spec in specs.items():\n            param = config[attr] if attr in config else None\n            if type(attr) is int:\n                path = f\'{name}[{attr}]\' if name != \'\' else attr\n            else:\n                path = f\'{name}.{attr}\' if name != \'\' else attr\n\n            if type(spec) is not dict:\n                config[attr] = spec\n            elif \'type\' in spec:\n                if param is None:\n                    if \'required\' not in spec or not spec[\'required\']:\n                        config[attr] = spec[\'default\'] if \'default\' in spec else None\n                        continue\n                    else:\n                        raise ConfigError(f\'Parameter "{attr}" is required.\')\n\n                if spec[\'type\'] == \'dict\':\n                    if type(param) == dict:\n                        if \'min\' in spec and spec[\'min\'] > len(param):\n                            raise ValueError(f\'Parameter "{path}" expected to have at \'\n                                f\'least {spec["min"]} elements but only found \'\n                                f\'{len(param)}.\')\n                        if \'max\' in spec and spec[\'max\'] < len(param):\n                            raise ValueError(f\'Parameter "{path}" expected to have at \'\n                                f\'most {spec["max"]} elements but found \'\n                                f\'{len(param)}.\')\n                        if \'options\' in spec and not all(k in spec[\'options\'] \n                                for k in param.keys()):\n                            valid = \'","\'.join(spec[\'options\'])\n                            invalid = \'","\'.join(k for k in param.keys() if \n                                k not in spec[\'options\'])\n                            raise ValueError(f\'Parameter "{path}" expected to only \'\n                                f\'"{valid}" for keys but found "{invalid}".\')\n                        if \'struct\' in spec:\n                            spec = {k: spec[\'struct\'] for k in param.keys()}\n                            config[attr] = self.verify_config(spec, param, name=path)\n                    else:\n                        raise TypeError(f\'Parameter "{path}" expected to be of type \'\n                            f\'"dict" but found "{type(param).__name__}".\')\n                elif spec[\'type\'] == \'list\':\n                    if type(param) == list:\n                        if \'min\' in spec and spec[\'min\'] > len(param):\n                            raise ValueError(f\'Parameter "{path}" expected to have at \'\n                                f\'least {spec["min"]} elements but only found \'\n                                f\'{len(param)}.\')\n                        if \'max\' in spec and spec[\'max\'] < len(param):\n                            raise ValueError(f\'Parameter "{path}" expected to have at \'\n                                f\'most {spec["max"]} elements but found \'\n                                f\'{len(param)}.\')\n                        if \'struct\' in spec:\n                            spec = {k: spec[\'struct\'] for k in range(len(param))}\n                            config[attr] = self.verify_config(spec,\n                                dict(enumerate(param)), name=path).values()\n                    else:\n                        raise TypeError(f\'Parameter "{path}" expected to be of type \'\n                            f\'"list" but found "{type(param).__name__}".\')\n                else:\n                    self.verify_param(path, spec, param)\n            else:\n                config[attr] = self.verify_config(spec, param, name=path)\n        \n        return config\n\n    \n    @classmethod\n    def verify_param(self, name, spec, param):\n        types = [self.types[t] for t in spec[\'type\'].split(\',\')]\n\n        if type(param) not in types:\n            types = \'", "\'.join(spec[\'type\'].split(\',\'))\n            raise TypeError(f\'Parameter "{name}" expected to be of type "\'\n                f\'{types}" but found "{type(param).__name__}".\')\n\n        if \'options\' in spec and len(spec[\'options\']) and param not in spec[\'options\']:\n            options = \', \'.join([f\'"{str(opt)}"\' for opt in spec[\'options\']])\n            raise ValueError(f\'Parameter "{name}" expected to be {options} \'\n                f\'but found "{param}".\')\n\n        if \'exceptions\' in spec and param in spec[\'exceptions\']:\n            raise ValueError(f\'Parameter "{name}" cannot be "{param}".\')\n\n        if \'min\' in spec and param < spec[\'min\']:\n            raise ValueError(f\'Parameter "{name}" expected to be greater than \'\n                f\'{spec["min"]} but found {name}.\')\n\n        if \'max\' in spec and param > spec[\'max\']:\n            raise ValueError(f\'Parameter "{name}" expected to be less than \'\n                f\'{spec["max"]} but found {param}.\')\n\n        if \'regex\' in spec and not re.search(spec[\'regex\'], param):\n            raise ValueError (f\'Parameter "{name}" expected to match pattern \'\n                f\'{spec["regex"]} but found "{param}".\')\n\n        # TODO complete error handling\n        if \'file\' in spec:\n            if spec[\'file\'] == \'exists\' and not self.file_exists(param):\n                raise ValueError()\n            elif spec[\'file\'] == \'readable\' and not self.file_readable(param):\n                raise ValueError()\n            elif spec[\'file\'] == \'writable\' and not self.file_writable(param):\n                raise ValueError()\n')
    __stickytape_write_module('knowledge/util/error.py', '\nclass ConfigError(Exception):\n    pass\n\nclass UserExitError(Exception):\n    pass')
    __stickytape_write_module('knowledge/model/association/model.py', '\nimport psutil\nimport pickle\nimport csv\n\nfrom collections import defaultdict\nfrom itertools import combinations\nfrom pkg_resources import resource_filename\n\nfrom knowledge.struct.fpgrowth import Fpgrowth\nfrom knowledge.util.config import ConfigUtil\nfrom knowledge.util.error import ConfigError, UserExitError\nfrom knowledge.util.print import PrintUtil as pr\n\ntry:\n    from knowledge.model.association.database import AssociationDatabase\n    mysql = True\nexcept:\n    mysql = False\n\nclass AssociationModel:\n    def __init__(self, database=None):\n        if not mysql and database is not None:\n            self.database = AssociationDatabase(database)\n        self.fpgrowth = None\n\n    @staticmethod\n    def chunk(arr, n):\n        for i in range(0, len(arr), n):\n            yield arr[i: i+n]\n\n    @staticmethod\n    def validate_config(configpath, specspath):\n        \'validates a configuration file for the association model\'\n\n        config = ConfigUtil.load_config(configpath)\n        specs = ConfigUtil.load_specs(specspath)\n        config = ConfigUtil.verify_config(specs, config)\n\n        tree = config[\'tree\']\n        association = config[\'associations\']        \n        if tree[\'load\']:\n            if tree[\'pickle\'] is None:\n                raise ConfigError(\'Pickled tree path must be given to\'\n                    \'load pickled tree.\')\n            if not ConfigUtil.file_readable(tree[\'pickle\']):\n                raise FileNotFoundError(\'Pickled tree path must be a \'\n                    \'path to a readable file.\')\n        if tree[\'save\']:\n            if tree[\'pickle\'] is None:\n                raise ConfigError(\'Pickled tree path must be given to\'\n                    \'save pickled tree.\')\n            if not ConfigUtil.file_writable(tree[\'pickle\']):\n                raise FileNotFoundError(\'Pickled tree path must be a \'\n                    \'path to a writable file or directory.\')\n        if association[\'csv\']:\n            if not ConfigUtil.file_writable(association[\'csv\']):\n                raise FileNotFoundError(\'Association csv path must be a \'\n                    \'path to a writable file or directory.\')\n\n        if not mysql and not tree[\'load\']:\n            raise ConfigError(\'No MySQL detected; cannot build tree without\'\n                \'MySQL environment.\')\n\n        if (not mysql and association[\'csv\'] is None \n                and not association[\'count_only\']):\n            raise ConfigError(\'No MySQL detected; must specify csv location \'\n                \'to save associations instead of table.\')\n\n        return config\n\n\n    def run(self, config, silent=None):\n        \'\'\'runs the fpgrowth model with specified configurations\n        Parameters\n        ----------\n        config: dict\n            A dictionary representation of the JSON config file.\n            See documentation for specifications of the config file.\n\n        Throws\n        ------\n        UserExitError\n            When prompted, the user chose to exit rather than procede.\n        \'\'\'\n\n        force = config[\'run\'][\'force\']\n        binsize = config[\'run\'][\'bin\']\n        write = not (config[\'items\'][\'count_only\'] or\n            config[\'patterns\'][\'count_only\'] or\n            config[\'associations\'][\'count_only\'])\n\n        if not write:\n            del self.database.tables[\'items\']\n            del self.database.tables[\'associations\']\n\n        pr.print(\'Preallocating tables/files for output.\', time=True)\n\n        if not force and config[\'tree\'][\'save\']:\n            save = config[\'tree\'][\'pickle\']\n            if ConfigUtil.file_exists(save):\n                cond = pr.print(f\'Patterns tree pickle file "{save}" already \'\n                    \'exists. Delete and continue? [Y/n] \', inquiry=True, \n                    time=True, force=True)\n                if not cond:\n                    raise UserExitError(\'User chose to terminate process.\')\n\n        if mysql:\n            self.create_tables(force)\n\n        if config[\'tree\'][\'load\']:\n            load = config[\'tree\'][\'pickle\']\n\n            pr.print(f\'Loading pickled patterns tree from "{load}".\', time=True)\n            self.fpgrowth = pickle.load(open(load, \'rb\'))\n            support = self.fpgrowth.support\n            popsize = self.fpgrowth.tree.root.count\n            items = [(key, val/popsize) for key, val in support.items()]\n\n            trans = self.fpgrowth.tree.root.count\n            events = sum(n.count for item in self.fpgrowth.tree.nodes.values()\n                for n in item) - trans\n            nodes = sum(len(item) for item in self.fpgrowth.tree.nodes.values())\n            pr.print(f\'Tree complete with {len(items)} items, {trans} transactions, \'\n                f\'{events} events, and {nodes} nodes.\', time=True)\n            \n            if write and mysql:\n                pr.print(f\'Pushing support for {len(support)} items to \'\n                    \'database.\', time=True)\n                self.database.write_rows(items, \'items\')\n        \n        else:\n            size = config[\'population\'][\'size\']\n            seed = config[\'population\'][\'seed\']\n\n            pr.print(f\'Generating sample population of size {size}.\', time=True)\n            population = self.generate_population(size, seed)\n            popsize = len(population)\n\n            min_support = config[\'items\'][\'min_support\']\n            max_support = config[\'items\'][\'max_support\']\n            source = config[\'items\'][\'source\']\n\n            pr.print(\'First data scan; calculating support for \'\n                \'population transactions.\', time=True)\n            support = self.calculate_support(population, source, min_support,\n                max_support, binsize, count_only=(not write))\n\n            pr.print(\'Second data scan; building frequent patterns tree.\', time=True)\n            self.fpgrowth = Fpgrowth(support)\n            self.build_tree(population, source, binsize)\n\n            items = len(self.fpgrowth.support)\n            trans = self.fpgrowth.tree.root.count\n            events = sum(n.count for item in self.fpgrowth.tree.nodes.values()\n                for n in item) - trans\n            nodes = sum(len(item) for item in self.fpgrowth.tree.nodes.values())\n            pr.print(f\'Tree complete with {items} items, {trans} transactions, \'\n                f\'{events} events, and {nodes} nodes.\', time=True)\n            \n\n        if config[\'tree\'][\'save\']:\n            save = config[\'tree\'][\'pickle\']\n\n            pr.print(f\'Saving pickled patterns tree to {save}.\', time=True)\n            pickle.dump(self.fpgrowth, open(save, \'wb\'))\n\n        min_support = config[\'patterns\'][\'min_support\']\n        max_support = config[\'patterns\'][\'max_support\']\n        max_size = config[\'patterns\'][\'max_size\']\n\n        pr.print(\'Beginning reading frequent patterns from tree.\', time=True)\n        count_only = config[\'patterns\'][\'count_only\']\n        patterns = self.find_patterns(min_support, max_support, max_size, \n            count_only=count_only)\n        del self.fpgrowth\n\n        if count_only:\n            pr.print(\'Assoication model run complete.\', time=True)\n            exit()\n\n        patterns = {frozenset(p[1]): p[0] / popsize for p in patterns}\n\n        pr.print(\'Analyzing patterns for significant associations.\', time=True)\n        conditions = config[\'associations\']\n        count_only = conditions[\'count_only\']\n        csvpath = conditions[\'csv\']\n        self.find_associations(patterns, conditions, popsize,\n            count_only=count_only, csvpath=csvpath)\n        del patterns\n\n        if count_only:\n            pr.print(\'Assoication model run complete.\', time=True)\n            exit()\n\n        index = config[\'run\'][\'index\']\n        if index:\n            pr.print(\'Creating indexes on all new tables.\', time=True)\n            for table in self.database.tables.keys():\n                self.database.create_all_idxs(table)\n\n        pr.print(\'Assoication model run complete.\', time=True)\n\n        \n    def generate_population(self, size, seed=None):\n        population = self.database.fetch_population(size, seed=seed)\n        popsize = len(population)\n        if size > popsize:\n            pr.print(f\'Requested population size of {size} but only \'\n                f\'found a max of {size} admissions.\', time=True)\n        return population\n\n\n    def create_tables(self, force=False):\n        if not force:\n            exists = self.database.table_exists(*list(self.database.tables.keys()))\n            tables = \'", "\'.join(exists)\n            if len(exists):\n                cond = pr.print(f\'Tables "{tables}" already exist in database \'\n                    f\'"{self.database.db}". Drop and continue? [Y/n] \', \n                    inquiry=True, time=True, force=True)\n                if not cond:\n                    raise UserExitError(\'User chose to terminate process.\')\n        for table in self.database.tables.keys():\n            self.database.create_table(table)\n        \n\n    def calculate_support(self, population, source, min_support, \n            max_support, binsize, count_only=False):\n        popsize = len(population)\n        min_support = int(min_support * popsize)\n        max_support = int(max_support * popsize)\n\n        support = defaultdict(int)\n        for subpop in self.chunk(population, binsize):\n            subjects, admissions = list(map(list, zip(*subpop)))\n\n            pr.print(f\'Fetching events for {len(subpop)} transactions.\', time=True)\n            events = self.database.fetch_events(source, subjects, admissions)\n\n            pr.print(f\'Calculating and merging support for {len(events)} \'\n                \'events.\', time=True)\n            items = set()\n            hadmid = 0\n            count = 0\n            for event in events:\n                if event[0] != hadmid:\n                    hadmid = event[0]\n                    for item in items:\n                        support[item] += 1\n                    items = set()\n                    count += 1\n                items.add(event[1])\n            del events\n\n        items = [(key, val/popsize) for key, val in support.items()\n            if val >= min_support and val <= max_support]\n        support = {key: val for key, val in support.items()\n            if val >= min_support and val <= max_support}\n\n        pr.print(f\'Found {len(items)} items in target population.\', time=True)\n        if not count_only:\n            pr.print(f\'Pushing support for {len(items)} items to database.\', time=True)\n            self.database.write_rows(items, \'items\')\n\n        return support\n\n        \n    def build_tree(self, population, source, bin_size):\n        for subpopulation in self.chunk(population, bin_size):\n            pr.print(f\'Fetching events for {len(subpopulation)}\'\n                \' transactions.\', time=True)\n\n            subjects, admissions = list(map(list, zip(*subpopulation)))\n            events = self.database.fetch_events(source, subjects, admissions)\n\n            pr.print(f\'Retrieved {len(events)} events; appending them\'\n                \' to the tree.\', time=True)\n            \n            transactions = []\n            items = set()\n            hadmid = 0\n            for event in events:\n                if event[0] != hadmid:\n                    hadmid = event[0]\n                    if len(items):\n                        transactions.append(items)\n                    items = set()\n                items.add(event[1])\n            del events\n\n            matrix, items = Fpgrowth.matrix(transactions)\n            del transactions\n\n            self.fpgrowth.build_tree(matrix, items)\n            del matrix\n            del items\n\n\n    def find_patterns(self, min_support, max_support, max_size, count_only=False):\n        min_support = int(min_support * self.fpgrowth.tree.root.count)\n        max_support = int(max_support * self.fpgrowth.tree.root.count)\n\n        observation_only = lambda items: all(i[0] == "O" for i in items)\n\n        patterns = []\n        generator = self.fpgrowth.find_patterns(self.fpgrowth.tree, \n            min_support, max_support, max_size)\n\n        count, n = 0, 1\n        for pattern in generator:\n            if count == n:\n                pr.print(f\'Found pattern {count}.\', time=True)\n                n = n << 1\n\n            if not observation_only(pattern[1]):\n                if not count_only:\n                    patterns.append(pattern)\n                count += 1\n\n        if count != n >> 1:\n            pr.print(f\'Found pattern {count}.\', time=True)\n\n        return patterns\n\n\n    def find_associations(self, patterns, conds, popsize, count_only=False, \n            csvpath=None):\n        if csvpath is not None:\n            csvfile = open(csv, \'w\', newline=\'\')\n            csvwriter = csv.writer(csvfile, delimiter=\',\', quotechar=\'"\')\n\n        inf = float(\'inf\')\n        metrics = {\n            \'support\':    lambda sAC, sA, sC: sAC,\n            \'confidence\': lambda sAC, sA, sC: sAC/sA,\n            \'lift\':       lambda sAC, sA, sC: sAC/sA/sC,\n            \'leverage\':   lambda sAC, sA, sC: sAC-sA*sC,\n            \'conviction\': lambda sAC, sA, sC: (1-sC)/(1-sAC/sA) if sAC != sA else inf,\n            \'rpf\':        lambda sAC, sA, sC: sAC*sAC/sA\n        }\n\n        associations = []\n        count, n = 0, 1\n\n        minmetrics = {cond[4:]: val for cond, val in conds.items() \n            if cond in (f\'min_{key}\' for key in metrics.keys())}\n        maxmetrics = {cond[4:]: val for cond, val in conds.items()\n            if cond in (f\'max_{key}\' for key in metrics.keys())}\n\n        for pattern in patterns.keys():\n            sAC = patterns[pattern]\n            for idx in range(len(pattern)-1,0,-1):\n                for subset in combinations(pattern, r=idx):\n                    antecedent = frozenset(subset)\n                    consequent = pattern - antecedent\n\n                    sA = patterns[antecedent]\n                    sC = patterns[consequent]\n\n                    score = all(metrics[metric](sAC, sA, sC) >= cond \n                        for metric, cond in minmetrics.items())\n                    \n                    score &= all(metrics[metric](sAC, sA, sC) <= cond \n                        for metric, cond in maxmetrics.items())\n\n                    if score and count_only:\n                        count += 1\n                        continue\n\n                    if score:\n                        if count == n:\n                            pr.print(f\'Found association {count}.\', time=True)\n                            n = n << 1\n\n                        if count_only:\n                            count += 1\n                            continue\n                        \n                        if count % 100000 == 0:\n                            if mysql:\n                                self.database.write_rows(associations, \'associations\')\n                            if csvpath is not None:\n                                csvwriter.writerows(associations)\n                                csvfile.flush()\n                            associations = []    \n                            \n                        associations.append((\n                            count,\n                            \',\'.join(sorted(antecedent)),\n                            \',\'.join(sorted(consequent)),\n                            metrics[\'support\'](sAC, sA, sC),\n                            metrics[\'confidence\'](sAC, sA, sC),\n                            metrics[\'lift\'](sAC, sA, sC),\n                            metrics[\'leverage\'](sAC, sA, sC),\n                            metrics[\'conviction\'](sAC, sA, sC) if sAC != sA else None,\n                            metrics[\'rpf\'](sAC, sA, sC)))\n                        count += 1                \n\n        if count != n >> 1:\n            pr.print(f\'Found association {count}.\', time=True)\n\n        if not count_only:\n            if mysql:\n                self.database.write_rows(associations, \'associations\')\n            if csvpath is not None:\n                csvwriter.writerows(associations)\n                csvfile.close()\n\n\n    def analyze_associations(self):\n        pass')
    __stickytape_write_module('knowledge/struct/fpgrowth.py', "\nimport psutil\n\nimport pandas as pd\nimport numpy as np\n\nfrom collections import defaultdict\nfrom itertools import combinations\n\nfrom knowledge.util.print import PrintUtil as pr\n\nclass Fpgrowth:\n    '''data structure and utilities for running fpgrowth algorithm\n\n    Parameters\n    ----------\n    support: dict\n        A dictionary mapping the names of items to their support.\n    '''\n\n    def __init__(self, support):\n        self.tree = Tree()\n        self.support = support\n    \n\n    @staticmethod\n    def matrix(transactions):\n        '''converts list of transactions into a sparse matrix\n\n        Parameters\n        ----------\n        transactions: list[list]\n            A list of transactions, which are each a list of items.\n\n            For example,\n            [[a, b, c, d],\n             [b, d],\n             [d, a, c],\n             [c, e, a]]\n\n        Returns\n        -------\n        matrix: numpy.ndarray\n            A numpy array representing the bool matrix of the transactions.\n\n            For example,\n            [[True,  True,  True,  True,  False],\n             [False, True,  False, True,  False],\n             [True,  False, True,  True,  False],\n             [False, False, True,  False, True ]]\n\n        items: tuple\n            A list containing the items names for the matrix, which \n            correspond to the columns of the matrix.\n\n            For example,\n            (a, b, c, d, e)\n        '''\n\n        unique = set()\n        for trans in transactions:\n            for item in trans:\n                unique.add(item)\n\n        matrix = np.zeros((len(transactions),len(unique)), dtype=bool)\n        items = {key: val for val, key in enumerate(unique)}\n\n        for idx, trans in enumerate(transactions):\n            for item in trans:\n                matrix[idx, items[item]] = True\n\n        return matrix, tuple(unique)\n\n\n    def build_tree(self, matrix, items, silent=False):\n        '''appends transactions to tree\n\n        Parameters\n        ----------\n        matrix: numpy.ndarray\n            A numpy array representing the bool matrix of the transactions.\n\n            For example,\n            [[True,  True,  True,  True,  False],\n             [False, True,  False, True,  False],\n             [True,  False, True,  True,  False],\n             [False, False, True,  False, True ]]\n\n        items: tuple\n            A list containing the items names for the matrix, which \n            correspond to the columns of the matrix. This set of items must be \n            a subset of the support attribute.\n\n            For example,\n            (a, b, c, d, e)\n\n        silent: bool = False\n            If true, this process will not print algorithm progress messages;\n            default is false.\n        '''\n\n        for i in range(len(matrix)):\n            itemset = [item for cond, item in zip(matrix[i], items) if cond \n                and item in self.support]\n            itemset.sort(key=self.support.get, reverse=True)\n            self.tree.insert_itemset(itemset)\n\n\n    def find_patterns(self, tree, min_support=0, max_support=1, max_size=0):\n        '''recursively reads frequent patterns off of tree\n        \n        Parameters\n        ----------\n        tree: Tree\n            The tree to read patterns from; this function will continue to\n            recursively itself with subtrees until the tree is a path or empty.\n\n        min_support: int\n            The minimum support of a pattern for it to be included in the\n            list of frequent patterns.\n\n        max_size: int\n\n\n        Yields\n        ------\n        pattern: tuple(float, list[str])\n        '''\n\n        items = tree.nodes.keys()\n        if tree.is_path():\n            size_remain = len(items) + 1\n            if max_size:\n                size_remain = max_size - len(tree.items) + 1\n            for i in range(1, size_remain):\n                for itemset in combinations(items, i):\n                    support = min([tree.nodes[i][0].count for i in itemset])\n                    yield support, tree.items + list(itemset)\n        elif max_size == 0  or max_size > len(tree.items):            \n            for item in items:\n                support = sum([node.count for node in tree.nodes[item]])\n                yield support, tree.items + [item]\n                \n            for item in items:\n                subtree = tree.conditional_tree(item, min_support, max_support)\n                for support, itemset in self.find_patterns(subtree, \n                        min_support, max_support, max_size):\n                    yield support, itemset\n\n\nclass Tree:\n    '''a tree structure with variable length, unordered children\n\n    Parameters\n    ----------\n    root: str/int/float = None\n        The value of the root node; default is None.\n    '''\n\n    def __init__(self, root=None):\n        self.root = Node(root)\n        self.nodes = defaultdict(list)\n        self.items = []\n    \n\n    def insert_itemset(self, itemset, count=1):\n        node = self.root\n        node.count += count\n\n        idx = 0\n        for item in itemset:\n            if item in node.children:\n                node = node.children[item]\n                node.count += count\n                idx += 1\n            else:\n                break\n\n        for item in itemset[idx:]:\n            child = Node(item, count=count, parent=node)\n            node.children[item] = child\n            self.nodes[item].append(child)\n            node = child\n            \n\n    def conditional_tree(self, cond, min_support, max_support):\n        branches = []\n        count = defaultdict(int)\n        for node in self.nodes[cond]:\n            branch = node.itempath()\n            branches.append(branch)\n            for item in branch:\n                count[item] += node.count\n                \n        items = [item for item in count if count[item] >= min_support\n            and count[item] <= max_support]\n        items.sort(key=count.get)\n        rank = {item: i for i, item in enumerate(items)}\n\n        tree = Tree()\n        tree.items = self.items + [cond]\n        for idx, branch in enumerate(branches):\n            branch = sorted([node for node in branch if node in rank],\n                key=rank.get, reverse=True)\n            tree.insert_itemset(branch, self.nodes[cond][idx].count)\n\n        return tree\n\n\n    def is_path(self):\n        node = self.root\n        while len(node.children) == 1:\n            node = list(node.children.values())[0]\n        return len(node.children) == 0\n\n\nclass Node:\n    '''an element in a tree structure\n\n    Parameters\n    ----------\n    item: str/int/float\n        A value describing the name of the item the node is associated with.\n    \n    count: int = 1\n        What value to initializ the count of the node on; default is 1.\n\n    parent: Node = None\n        The parent node of the node being constructed; default is None type.\n    '''\n\n    def __init__(self, item, count=1, parent=None):\n        self.item = item\n        self.count = count\n        self.children = {}\n        self.parent = parent\n\n\n    def itempath(self):\n        path = []\n        parent = self.parent\n        while parent.item is not None:\n            path.append(parent.item)\n            parent = parent.parent\n        path.reverse()\n        return path")
    __stickytape_write_module('knowledge/struct/__init__.py', '')
    __stickytape_write_module('knowledge/model/association/database.py', '\nfrom knowledge.util.database import DatabaseUtil\n\nclass AssociationDatabase(DatabaseUtil):\n    def fetch_population(self, size, seed=None):\n        seed = seed if seed is not None else \'\'\n        query = f\'\'\'\n            SELECT\n                SUBJECT_ID,\n                HADM_ID\n            FROM mimiciiiv14.ADMISSIONS\n            ORDER BY RAND({seed})\n            LIMIT {size}\n        \'\'\'\n        self.cursor.execute(query)\n        return self.cursor.fetchall()\n\n\n    def fetch_events(self, source, subjects, admissions):\n        subquery = {}\n        subquery[\'observations\'] = f\'\'\'\n            SELECT\n                lab.HADM_ID,\n                CONCAT("O-", item.LOINC_CODE)\n            FROM mimiciiiv14.LABEVENTS AS lab\n            INNER JOIN mimiciiiv14.D_LABITEMS AS item\n            USING(ITEMID)\n            WHERE lab.SUBJECT_ID IN {tuple(subjects)}\n            AND lab.HADM_ID IN {tuple(admissions)}\n            AND item.LOINC_CODE IS NOT NULL \'\'\'\n        subquery[\'conditions\'] = f\'\'\'\n            SELECT\n                HADM_ID,\n                CONCAT("C-", ICD9_CODE)\n            FROM mimiciiiv14.DIAGNOSES_ICD\n            WHERE SUBJECT_ID IN {tuple(subjects)}\n            AND HADM_ID IN {tuple(admissions)} \n            AND ICD9_CODE IS NOT NULL \'\'\'\n        subquery[\'treatments\'] = f\'\'\'\n            SELECT\n                HADM_ID,\n                CONCAT("T-", NDC)\n            FROM mimiciiiv14.PRESCRIPTIONS\n            WHERE SUBJECT_ID IN {tuple(subjects)}\n            AND HADM_ID IN {tuple(admissions)}\n            AND NDC IS NOT NULL\'\'\'\n        subquery = {key: val for key, val in subquery.items() if key in source}\n        query = \'\\nUNION\\n\'.join(subquery.values())\n        query += \'\\nORDER BY HADM_ID\'\n        self.cursor.execute(query)\n        return self.cursor.fetchall()\n\n    def count_by_concept(self):\n        query = f\'\'\'\n            SELECT\n                SUM((CHAR_LENGTH(antecedent) - \n                    CHAR_LENGTH(REPLACE(antecedent, "O-", ""))) / 2\n                ) AS `ante-obs`,\n                SUM((CHAR_LENGTH(antecedent) - \n                    CHAR_LENGTH(REPLACE(antecedent, "T-", ""))) / 2\n                ) AS `ante-trt`,\n                SUM((CHAR_LENGTH(antecedent) - \n                    CHAR_LENGTH(REPLACE(antecedent, "C-", ""))) / 2\n                ) AS `ante-con`,\n                SUM((CHAR_LENGTH(consequent) - \n                    CHAR_LENGTH(REPLACE(consequent, "O-", ""))) / 2\n                ) AS `cons-obs`,\n                SUM((CHAR_LENGTH(consequent) - \n                    CHAR_LENGTH(REPLACE(consequent, "T-", ""))) / 2\n                ) AS `cons-trt`,\n                SUM((CHAR_LENGTH(consequent) - \n                    CHAR_LENGTH(REPLACE(consequent, "C-", ""))) / 2\n                ) AS `cons-con`\n            FROM {self.db}.associations\n        \'\'\'\n\n    ')
    __stickytape_write_module('knowledge/util/database.py', '\nimport MySQLdb\nimport warnings\n\nfrom knowledge.util.print import PrintUtil as pr\nfrom knowledge.util.error import UserExitError\n\nwarnings.filterwarnings(\'ignore\', category=MySQLdb._exceptions.Warning)\n\nclass DatabaseUtil:\n    def __init__(self, params=None, database=None):\n        if type(database) is DatabaseUtil:\n            self = database\n        elif type(params) is dict:\n            keys = (\'user\', \'password\', \'db\', \'host\', \'unix_socket\')\n            login = {key:params[key] for key in keys if key in params}\n            self.user = params[\'user\']\n            self.host = params[\'host\']\n            self.db = params[\'db\']\n            self.tables = params[\'tables\'] if \'tables\' in params else {}\n            try:\n                self.connection = MySQLdb.connect(**login)\n                self.cursor = self.connection.cursor()\n            except MySQLdb._exceptions.OperationalError as err:\n                if err.args[0] == 1049:\n                    term = pr.print(f\'Database "{self.db}" does not exist. Create \'\n                        \'and continue? [Y/n] \', time=True, \n                        inquiry=True, force=True)\n                    if term:\n                        del login[\'db\']\n                        connection = MySQLdb.connect(**login)\n                        cursor = connection.cursor()\n                        cursor.execute(f\'CREATE DATABASE {params["db"]}\')\n                        connection.commit()\n                        cursor.close()\n                        connection.close()\n                        login[\'db\'] = self.db\n                        self.connection = MySQLdb.connect(**login)\n                        self.cursor = self.connection.cursor()\n                    else:\n                        raise UserExitError(\'User chose to terminate process.\')\n                else:\n                    raise err\n\n    def drop_table(self, table):\n        query = f\'DROP TABLE IF EXISTS {self.db}.{table}\'\n        self.cursor.execute(query)\n        self.connection.commit()\n\n    def table_exists(self, *tables):\n        conditions = f\'" or `Tables_in_{self.db}` like "\'.join(tables)\n        query = f\'\'\'\n            SHOW TABLES FROM {self.db}\n            WHERE `Tables_in_{self.db}` like "{conditions}"\'\'\'\n        self.cursor.execute(query)\n        return [row[0] for row in self.cursor.fetchall()]\n\n    def create_table(self, table):\n        table_data = self.tables[table]\n        sql_schema = (\', \').join(table_data[\'schema\'])\n        query = f\'DROP TABLE IF EXISTS {self.db}.{table}\'\n        self.cursor.execute(query)\n        self.connection.commit()\n        query = f\'CREATE TABLE {self.db}.{table} ({sql_schema})\'\n        self.cursor.execute(query)\n        self.connection.commit()\n\n    def create_index(self, table, name):\n        columns = (\', \').join(self.tables[table][\'indexes\'][name])\n        query = f\'\'\'\n            CREATE INDEX {name}\n            ON {self.db}.{table} ({columns})\'\'\'\n        self.cursor.execute(query)\n        self.connection.commit()\n\n    def create_primary_idx(self, table):\n        cols = \', \'.join(self.tables[table][\'primary_idx\'])\n        query = f\'\'\'\n            ALTER TABLE {self.db}.{table}\n            ADD PRIMARY KEY ({cols})\'\'\'\n        self.cursor.execute(query)\n        self.connection.commit()\n\n    def create_hash_idx(self, table, name):\n        cols = \', \'.join(self.tables[table][\'hash_idxs\'][name])\n        query = f\'\'\'\n            CREATE INDEX {name} USING HASH\n            ON {self.db}.{table} ({cols})\'\'\'\n        self.cursor.execute(query)\n        self.connection.commit()        \n\n    def create_btree_idx(self, table, name):\n        cols = \', \'.join(self.tables[table][\'btree_idxs\'][name])\n        query = f\'\'\'\n            CREATE INDEX {name}\n            ON {self.db}.{table} ({cols})\'\'\'\n        self.cursor.execute(query)\n        self.connection.commit()   \n    \n    def create_spatial_idx(self, table, name):\n        cols = \', \'.join(self.tables[table][\'spatial_idxs\'][name])\n        query = f\'\'\'\n            CREATE SPATIAL INDEX {name}\n            ON {self.db}.{table} ({cols})\'\'\'\n        self.cursor.execute(query)\n        self.connection.commit()\n\n    def create_fulltext_idx(self, table, name):\n        cols = \', \'.join(self.tables[table][\'fulltext_idxs\'][name])\n        query = f\'\'\'\n            CREATE FULLTEXT INDEX {name}\n            ON {self.db}.{table} ({cols})\'\'\'\n        self.cursor.execute(query)\n        self.connection.commit()       \n    \n    def create_all_idxs(self, table):\n        tbl_data = self.tables[table]\n        if \'primary_idx\' in tbl_data and tbl_data[\'primary_idx\'] is not None:\n            if len(tbl_data[\'primary_idx\']):\n                pr.print(f\'Creating primary index on table "{table}".\', time=True)\n                self.create_primary_idx(table)\n        if \'spatial_idxs\' in tbl_data and tbl_data[\'spatial_idxs\'] is not None:\n            for idx in tbl_data[\'spatial_idxs\']:\n                pr.print(f\'Creating spatial index "{idx}" on \'\n                    f\'table "{table}".\', time=True)\n                self.create_spatial_idx(table, idx)\n        if \'hash_idxs\' in tbl_data and tbl_data[\'hash_idxs\'] is not None:\n            for idx in tbl_data[\'hash_idxs\']:\n                pr.print(f\'Creating hash index "{idx}" on \'\n                    f\'table "{table}".\', time=True)\n                self.create_hash_idx(table, idx)\n        if \'btree_idxs\' in tbl_data and tbl_data[\'btree_idxs\'] is not None:\n            for idx in tbl_data[\'btree_idxs\']:\n                pr.print(f\'Creating btree index "{idx}" on \'\n                    f\'table "{table}".\', time=True)\n                self.create_btree_idx(table, idx)\n        if \'fulltext_idxs\' in tbl_data and tbl_data[\'fulltext_idxs\'] is not None:\n            for idx in tbl_data[\'fulltext_idxs\']:\n                pr.print(f\'Creating fulltext index "{idx}" on \'\n                    f\'table "{table}".\', time=True)\n                self.create_fulltext_idx(table, idx)\n\n    def write_rows(self, data, table):\n        s_strs = \', \'.join([\'%s\'] * len(self.tables[table][\'schema\']))\n        query = f\'\'\' \n            INSERT INTO {self.db}.{table}\n            VALUES ({s_strs}) \'\'\'\n        self.cursor.executemany(query, data)\n        self.connection.commit()\n')
    __stickytape_write_module('knowledge/model/__init__.py', '')
    __stickytape_write_module('knowledge/model/association/__init__.py', '')
    
    import json
    import sys
    
    from pkg_resources import resource_filename
    from argparse import ArgumentParser
    
    from knowledge.util.print import PrintUtil as pr
    from knowledge.util.config import ConfigUtil
    from knowledge.model.association.model import AssociationModel
    
    # needed for pickling/unpickling large trees
    sys.setrecursionlimit(10000)
    
    # command line argumetn parsing
    parser = ArgumentParser(prog='association model runner',
        description='run an association building model')
    parser.add_argument('--config', type=str, dest='config', default=None,
        help=('specify a config file location; default is "config.json" in '
            'this this module\'s build directory'))
    parser.add_argument('--specs', type=str, dest='specs', default=None,
        help=('specify a specs file location; default is "specs.json" in '
            'this this module\'s build directory'))
    parser.add_argument('--pkg', type=bool, dest='pkg', default=True,
        help=('specify whether or not script is being run as package; '
            'without package mode, MySQL connections cannot be used '
            'and --config and --specs arguments are required'))
    parser.add_argument('--log', type=str, dest='log', default=None,
        help='specify a log file location; by default the log will not be saved')
    args = parser.parse_args()
    
    # load default config/specs files if not passed via command line arguments
    # when running without package, default config/specs will not load
    if args.pkg is False and (args.config is None or args.specs is None):
        pr.print('When running as standalone, --config and --specs ' 
            'are required')
    try:
        if args.config is None:
            args.config = resource_filename('knowledge', 'model/association/config.json')
        if args.specs is None:
            args.specs = resource_filename('knowledge', 'model/association/config.json')
    except:
        pr.print('Default config/specs file not found; fix packaging or, if'
            'not running as a package, specify a config and specs with '
            '--config and --specs.', time=True)
        quit()
        
    # validate config file against specs file
    config = AssociationModel.validate_config(args.config, args.specs)
    
    if config['run']['silent']:
        pr.silence()
    
    # add log if in arguments or config
    if args.log is not None:
        pr.log(args.log)
    elif config['run']['log'] is not None:
        pr.log(config['run']['log'])
    
    # prompt for SQL password if running as package
    if not args.pkg:
        database = config['database']
        database['password'] = pr.getpass(f'SQL password for {database["user"]}'
            '@localhost: ', time=True)
    else:
        database = None
    
    # run model
    model = AssociationModel(database)
    model.run(config)